spring.application.name=multiChatClient

# Logging
logging.pattern.console=%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) - %msg%n
logging.level.org.springframework.ai.chat.client.advisor=DEBUG

# Spring AI / Ollama Configuration using Docker hosted ollama
spring.ai.ollama.chat.options.model=gemma3:1b
spring.ai.openai.api-key=${OPENAI_KEY}
# By default, Spring AI autoconfigures a single ChatClient.Builder bean. However, you may need to work with multiple chat models in your application.
# In all cases, you need to disable the ChatClient.Builder autoconfiguration
# This allows you to create multiple ChatClient instances manually.
spring.ai.chat.client.enabled=false

#spring.ai.ollama.base-url=http://localhost:11434